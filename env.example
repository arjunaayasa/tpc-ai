# PostgreSQL connection
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=SCHEMA
DATABASE_URL="postgresql://postgres:yourpassword@localhost:5432/taxkb?schema=public"

# Redis connection (required for background worker)
REDIS_URL="redis://localhost:6379"

# Upload directory (relative to project root)
UPLOAD_DIR="./uploads"

# ============== RAG Configuration ==============

# Embedding Provider: 'tei' or 'ollama'
EMBEDDING_PROVIDER="ollama"

# Embedding service URL
# For Ollama: http://localhost:11434
# For TEI: http://localhost:8080
EMBEDDING_BASE_URL="http://localhost:11434"

# Embedding model name
# For Ollama: nomic-embed-text, mxbai-embed-large, all-minilm
# For TEI: depends on model loaded
EMBEDDING_MODEL="nomic-embed-text"

# Embedding dimension (must match model output)
# nomic-embed-text: 768
# mxbai-embed-large: 1024
# bge-base-en-v1.5: 768
EMBEDDING_DIM="1024"

# ============== LLM Configuration ==============

# Ollama base URL for chat/generation
OLLAMA_BASE_URL="http://localhost:11434"

# LLM model for RAG answers
# Recommended: qwen2.5:7b-instruct, llama3.1:8b-instruct, mistral:7b-instruct
OLLAMA_MODEL="qwen2.5:7b-instruct"

# ============== Alibaba ModelStudio (Qwen) Configuration ==============
# Used for cloud AI chat and parsing tables from PDF
# Get API key from: https://dashscope.console.aliyun.com/ (International)
# or https://bailian.console.aliyun.com/ (China)

# Qwen API Key
QWEN_API_KEY=""

# Base URL (use -intl for international/Singapore region)
QWEN_BASE_URL="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"

# Available models for chat:
# - qwen-plus: Fast general purpose
# - qwen-max: Most powerful
# - qwq-plus: Reasoning/thinking model
QWEN_MODEL="qwen-plus"
QWEN_THINKING_MODEL="qwq-plus"
QWEN_MAX_MODEL="qwen-max"
