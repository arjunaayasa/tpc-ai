# PostgreSQL connection
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=SCHEMA
DATABASE_URL="postgresql://postgres:yourpassword@localhost:5432/taxkb?schema=public"

# Redis connection (required for background worker)
REDIS_URL="redis://localhost:6379"

# Upload directory (relative to project root)
UPLOAD_DIR="./uploads"

# ============== RAG Configuration ==============

# Embedding Provider: 'tei' or 'ollama'
EMBEDDING_PROVIDER="ollama"

# Embedding service URL
# For Ollama: http://localhost:11434
# For TEI: http://localhost:8080
EMBEDDING_BASE_URL="http://localhost:11434"

# Embedding model name
# For Ollama: nomic-embed-text, mxbai-embed-large, all-minilm
# For TEI: depends on model loaded
EMBEDDING_MODEL="nomic-embed-text"

# Embedding dimension (must match model output)
# nomic-embed-text: 768
# mxbai-embed-large: 1024
# bge-base-en-v1.5: 768
EMBEDDING_DIM="1024"

# ============== LLM Configuration ==============

# Ollama base URL for chat/generation
OLLAMA_BASE_URL="http://localhost:11434"

# LLM model for RAG answers
# Recommended: qwen2.5:7b-instruct, llama3.1:8b-instruct, mistral:7b-instruct
OLLAMA_MODEL="qwen2.5:7b-instruct"
